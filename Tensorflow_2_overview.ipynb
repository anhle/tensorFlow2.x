{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_2_overview.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/tensorFlow2.x/blob/master/Tensorflow_2_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qi57KVrgEX9Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#TensorFlow Overview \n",
        "\n",
        "A quick look at some MNIST examples to get familiar with the core features of TensorFlow 2.0:\n",
        "\n",
        "- tf.keras: A high-level, object-oriented API for fast prototyping of deep learning models\n",
        "- tf.GradientTape: Records gradients on-the-fly for automatic differentiation and backprop\n",
        "- tf.train: Optimizers for training and checkpoints for exporting models\n"
      ]
    },
    {
      "metadata": {
        "id": "GEHzrkMPFKZA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train MNIST with a convolutional network:\n",
        "\n",
        "To get started, import the TensorFlow library into your program:"
      ]
    },
    {
      "metadata": {
        "id": "vkTWRwuWGoGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "13c2b44d-7cbc-4af4-e8e8-0f4938ea9edd"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from   tensorflow.python.ops import summary_ops_v2\n",
        "from   tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "\n",
        "import  os\n",
        "import  time\n",
        "import  numpy as np\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 79.9MB 403kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 12.4MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 29.3MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 419kB 23.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OYU4aIGCHNeU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load and prepare the MNIST dataset. Convert the samples from integers to floating-point numbers:"
      ]
    },
    {
      "metadata": {
        "id": "ivzAbyZ9HSTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_types(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "  return image, label\n",
        "\n",
        "dataset, info = tfds.load('mnist', data_dir='gs://tfds-data/datasets', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = dataset['train'], dataset['test']\n",
        "\n",
        "mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(32)\n",
        "mnist_test = mnist_test.map(convert_types).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pko4G1ywHnGS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the tf.keras model using the Keras model subclassing API.  Choose an optimizer and loss function used for training:"
      ]
    },
    {
      "metadata": {
        "id": "-WkwqNUaHpl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vimouPMZB6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "metadata": {
        "id": "Qki5nz5PZHvC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGy_Eu28Odcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train and evaluate model:\n",
        "* Train the model using tf.GradientTape:"
      ]
    },
    {
      "metadata": {
        "id": "N0IXD3MROe3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(image, label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(image)\n",
        "    loss = loss_object(label, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(label, predictions)\n",
        "  \n",
        "@tf.function\n",
        "def test_step(image, label):\n",
        "  predictions = model(image)\n",
        "  t_loss = loss_object(label, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(label, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OH2Az4GEPAX1",
        "colab_type": "code",
        "outputId": "1d1f694e-2a22-471f-e65f-accd9c758e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "# Where to save checkpoints, tensorboard summaries, etc.\n",
        "MODEL_DIR = '/mnist'\n",
        "\n",
        "checkpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
        "\n",
        "# Restore variables on creation if a checkpoint exists.\n",
        "#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    \n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for image, label in mnist_train:\n",
        "    start = time.time()\n",
        "    train_step(image, label)\n",
        "    end = time.time()\n",
        "    \n",
        "\n",
        "  for test_image, test_label in mnist_test:\n",
        "    test_step(test_image, test_label)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "  \n",
        "  checkpoint.save(checkpoint_prefix)\n",
        "  print('saved checkpoint.')\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, 'export')\n",
        "tf.saved_model.save(model, export_path)\n",
        "print('saved SavedModel for exporting.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.13342660665512085, Accuracy: 95.91500091552734, Test Loss: 0.06172272190451622, Test Accuracy: 97.93999481201172\n",
            "saved checkpoint.\n",
            "Epoch 2, Loss: 0.08763611316680908, Accuracy: 97.2925033569336, Test Loss: 0.0593315027654171, Test Accuracy: 98.06999969482422\n",
            "saved checkpoint.\n",
            "Epoch 3, Loss: 0.06628486514091492, Accuracy: 97.94166564941406, Test Loss: 0.05797857046127319, Test Accuracy: 98.15999603271484\n",
            "saved checkpoint.\n",
            "Epoch 4, Loss: 0.05331886559724808, Accuracy: 98.3387451171875, Test Loss: 0.05735132098197937, Test Accuracy: 98.21749877929688\n",
            "saved checkpoint.\n",
            "Epoch 5, Loss: 0.0444309264421463, Accuracy: 98.61067199707031, Test Loss: 0.059119150042533875, Test Accuracy: 98.26399993896484\n",
            "saved checkpoint.\n",
            "saved SavedModel for exporting.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}