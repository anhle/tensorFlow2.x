{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression_bostonHousing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/tensorFlow2.x/blob/master/Linear_Regression_bostonHousing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "S3t0wHWht0bK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linear Regressing \n",
        "the Boston housing dataset is real data and has 13 features. This is a regression problem because house prices—the label—we take as being continuously valued.\n",
        "In a regression problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a classification problem, where we aim to select a class from a list of classes (for example, where a picture contains an apple or an orange, recognizing which fruit is in the picture)."
      ]
    },
    {
      "metadata": {
        "id": "fKPU0Cq-uDg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3fd73ffd-e77e-406d-80db-aa441ba6dba8"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow==2.0.0-alpha0\n",
        "\n",
        "import  tensorflow as tf\n",
        "import  numpy as np\n",
        "from    tensorflow import keras\n",
        "import  os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 79.9MB 351kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.7MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 419kB 21.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 11.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ifDOfUMUxUvo"
      },
      "cell_type": "markdown",
      "source": [
        "We scale the inputs to have mean 0 and standard variation 1."
      ]
    },
    {
      "metadata": {
        "id": "61THYE20weiO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(22)\n",
        "np.random.seed(22)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "assert tf.__version__.startswith('2.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0veo8mLTxVcw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(X_train, X_test):\n",
        "    # this function normalize inputs for zero mean and unit variance\n",
        "    # it is used when training a model.\n",
        "    # Input: training set and test set\n",
        "    # Output: normalized training set and test set according to the trianing set statistics.\n",
        "\n",
        "    mean = np.mean(X_train)\n",
        "    std = np.std(X_train)\n",
        "    print('mean:', mean, 'std:', std)\n",
        "    X_train = (X_train - mean) / (std + 1e-7)\n",
        "    X_test = (X_test - mean) / (std + 1e-7)\n",
        "    return X_train, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSNW9s0zyMR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d904eada-f8b1-41a6-c5a9-f59eba926557"
      },
      "cell_type": "code",
      "source": [
        "def boston_dataset():\n",
        "\n",
        "  (x_train, y_train), (x_val, y_val) = keras.datasets.boston_housing.load_data()\n",
        "\n",
        "  x_train, x_val = x_train.astype(np.float32), x_val.astype(np.float32)\n",
        "  print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
        "  x_train, x_val = normalize(x_train, x_val)\n",
        "  \n",
        "  db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
        "  db_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(102)\n",
        "  \n",
        "  return db_train,db_val\n",
        "\n",
        "db_train,db_val = boston_dataset()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "(404, 13) (404,) (102, 13) (102,)\n",
            "mean: 69.79277 std: 144.39195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "swQ51RdR0eCf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Implement linear regression by sub-class keras.layers.Layer.\n",
        "\n",
        "A linear regression is evaluated with an equation. The variable y is explained by one or many covariates. In your example, there is only one dependent variable. If you have to write this equation, it will be:\n",
        "\n",
        "$$ y = wX + \\beta$$\n"
      ]
    },
    {
      "metadata": {
        "id": "wBMZOdNLuYX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bb8da2f8-1ee4-4ba1-a9aa-2f7342bc967b"
      },
      "cell_type": "code",
      "source": [
        "class Regressor(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "\n",
        "        # here must specify shape instead of tensor !\n",
        "        # name here is meanless !\n",
        "        # [dim_in, dim_out]\n",
        "        self.w = self.add_variable('meanless-name', [13, 1])\n",
        "        # [dim_out]\n",
        "        self.b = self.add_variable('meanless-name', [1])\n",
        "\n",
        "        print(self.w.shape, self.b.shape)\n",
        "        print(type(self.w), tf.is_tensor(self.w), self.w.name)\n",
        "        print(type(self.b), tf.is_tensor(self.b), self.b.name)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        x = tf.matmul(x, self.w) + self.b\n",
        "\n",
        "        return x\n",
        "      \n",
        "\n",
        "model = Regressor()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13, 1) (1,)\n",
            "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n",
            "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CAwTBKegvBly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criteon = keras.losses.MeanSquaredError()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDfaZ8qD0NWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " for epoch in range(200):\n",
        "\n",
        "      for step, (x, y) in enumerate(db_train):\n",
        "\n",
        "          with tf.GradientTape() as tape:\n",
        "              # [b, 1]\n",
        "              logits = model(x)\n",
        "              # [b]\n",
        "              logits = tf.squeeze(logits, axis=1)\n",
        "              # [b] vs [b]\n",
        "              loss = criteon(y, logits)\n",
        "\n",
        "          grads = tape.gradient(loss, model.trainable_variables)\n",
        "          optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      print(epoch, 'loss:', loss.numpy())\n",
        "\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "\n",
        "          for x, y in db_val:\n",
        "              # [b, 1]\n",
        "              logits = model(x)\n",
        "              # [b]\n",
        "              logits = tf.squeeze(logits, axis=1)\n",
        "              # [b] vs [b]\n",
        "              loss = criteon(y, logits)\n",
        "\n",
        "              print(epoch, 'val loss:', loss.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L36mT6edvXRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Another way training data\n",
        "\n",
        "### Define the loss and gradient function\n",
        "Both training and evaluation stages need to calculate the model's loss. This measures how off a model's predictions are from the desired label, in other words, how bad the model is performing. We want to minimize, or optimize, this value.\n",
        "\n",
        "* Our model will calculate its loss using the tf.keras.losses.SparseCategoricalCrossentropy function which takes the model's class probability predictions and the desired label, and returns the average loss across the examples.\n",
        "\n",
        "* An optimizer applies the computed gradients to the model's variables to minimize the loss function. You can think of the loss function as a curved surface and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascent—so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Htk3SbIEvm0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "metadata": {
        "id": "XJgQLTynwIhC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model using tf.GradientTape:"
      ]
    },
    {
      "metadata": {
        "id": "V86XSuRO5oNR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training loop\n",
        "With all the pieces in place, the model is ready for training! A training loop feeds the dataset examples into the model to help it make better predictions. The following code block sets up these training steps:\n",
        "\n",
        "1. Iterate each epoch. An epoch is one pass through the dataset.\n",
        "2. Within an epoch, iterate over each example in the training Dataset grabbing its features (x) and label (y).\n",
        "3. Using the example's features, make a prediction and compare it with the label. Measure the inaccuracy of the prediction and use that to calculate the model's loss and gradients.\n",
        "4. Use an optimizer to update the model's variables.\n",
        "5. Keep track of some stats for visualization.\n",
        "6. Repeat for each epoch."
      ]
    }
  ]
}